{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect-Four Game\n",
    "\n",
    "Connect-four is a board game with a $6\\times 7$ grid. Each player has $21$ checkers distinguished by black (B) and red (R) colors. The board is a vertical board and player can only drop their checkers from the top in any of the $7$ columns if the column is not full.\n",
    "\n",
    "Each player alternate dropping a checker from the top until:\n",
    "\n",
    "* A player makes a row, a column, or a diagonal set of $4$ checkers.\n",
    "* No moves left and no sets are made by any player. This case is a draw.\n",
    "\n",
    "We first set up a game which can be used for human-versus-human play. Then, we explain the Monte Carlo Tree Search (MCTS) algorithm and use it for human-versus-machine and machine-versus-machine plays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players={1: \"B\", -1: \"R\", 0: \".\"}\n",
    "\n",
    "def print_state(state):\n",
    "    print(\"\\n\\t\", end=\"\")\n",
    "    print(\"\\n\\t\".join(\"  \".join([players[col] for col in row]) for row in state))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect-Four Game Setup\n",
    "\n",
    "We first set up a human-versus-human play. The algorithm calculates when a player wins or there's no move to make (draw) and terminates the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Connect4(object):\n",
    "    def __init__(self):\n",
    "        # Grid shape.\n",
    "        self.nrows = 6\n",
    "        self.ncols = 7\n",
    "        # number of connections to be made for winning.\n",
    "        self.k = 4\n",
    "        self.first_player = 1\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__\n",
    "\n",
    "    def init_state(self):\n",
    "        return np.zeros((self.nrows, self.ncols), dtype=np.int8)\n",
    "\n",
    "    def next_state(self, state, action, player):\n",
    "        \"\"\"\n",
    "        Returns the new state resulted by applying `action` taken by `player`\n",
    "        on the current `state`.\n",
    "        \"\"\"\n",
    "        col = action\n",
    "        row = np.argwhere(state[:, col] == 0)[-1][0]\n",
    "        state[row, col] = player\n",
    "        return state\n",
    "\n",
    "    def available_actions(self, state):\n",
    "        return np.where(state[0, :] == 0)[0]\n",
    "\n",
    "    def opponent(self, player):\n",
    "        return -player\n",
    "\n",
    "    def opponent_reward(self, reward):\n",
    "        return -reward\n",
    "\n",
    "    def neutral_perspective(self, state, player):\n",
    "        return player * state\n",
    "\n",
    "    def won(self, state, action):\n",
    "        \"\"\"\n",
    "        Returns true if `action` taken resulted in a winnng `state`.\n",
    "        \"\"\"\n",
    "        if action is None:\n",
    "            return False\n",
    "\n",
    "        col = action\n",
    "        # Find the first nonzero element in this column\n",
    "        row = np.argwhere(state[:, col] != 0)[0][0]\n",
    "        player = state[row, col]\n",
    "\n",
    "        for i in range(self.nrows - self.k + 1):\n",
    "            total = np.sum(state[i : i + self.k, col])\n",
    "            if total == self.k * player:\n",
    "                return True\n",
    "\n",
    "        for j in range(self.ncols - self.k + 1):\n",
    "            total = np.sum(state[row, j : j + self.k])\n",
    "            if total == self.k * player:\n",
    "                return True\n",
    "\n",
    "        diag = np.diag(state, col - row)\n",
    "        for j in range(len(diag) - self.k + 1):\n",
    "            total = np.sum(diag[j : j + self.k])\n",
    "            if total == self.k * player:\n",
    "                return True\n",
    "\n",
    "        flipped_col = self.ncols - col - 1\n",
    "        diag = np.diag(np.fliplr(state), flipped_col - row)\n",
    "        for j in range(len(diag) - self.k + 1):\n",
    "            total = np.sum(diag[j : j + self.k])\n",
    "            if total == self.k * player:\n",
    "                return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def is_over(self, state, action):\n",
    "        if self.won(state, action):\n",
    "            return 1\n",
    "        if np.sum(state[0, :] == 0) == 0:\n",
    "            return 0\n",
    "        return -1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human-Human Play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = Connect4()\n",
    "player = game.first_player\n",
    "state = game.init_state()\n",
    "\n",
    "while True:\n",
    "    print_state(state)\n",
    "    print(f\"player {players[player]} is to play...\")\n",
    "    \n",
    "    available_actions = game.available_actions(state)\n",
    "    print(f\"available actions: {game.available_actions(state)}\")\n",
    "    \n",
    "    action = int(input(\"provide a valid move: \"))\n",
    "    state = game.next_state(state, action, player)\n",
    "    \n",
    "    is_over = game.is_over(state, action)\n",
    "    if is_over >= 0:\n",
    "        print_state(state)\n",
    "        if is_over == 0:\n",
    "            print(\"draw!\")\n",
    "        else:\n",
    "            print(f\"player {players[player]} won!\")\n",
    "        break\n",
    "        \n",
    "    player = game.opponent(player)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Tree Search\n",
    "\n",
    "In this setion, we design a machine that can play against human or against another machine. We use Monte Carlo Tree Search (MCTS) to decide on the next move.\n",
    "\n",
    "For a machine to be able to play against itself, we design it in a way that is agnostic of the player. We can assume that the player is always player 1, and change the perspective so that the machine acts as player -1. For calrification, consider the following state in a $6\\times 7$ Connect-4 game:\n",
    "\n",
    "$$\n",
    "S = \n",
    "\\begin{pmatrix}\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 1 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & -1 & 1 & -1 & 0 & 0 & 0 \\\\\n",
    "1 & 1 & 1 & -1 & -1 & 0 & 0\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Player -1 is to play. We can see this is equvalent to player 1 in state $-S$, where all elements are multiplied by $-1$. Thus, we can design MCTS algorithm which is player agnostic.\n",
    "\n",
    "The MCTS algorithms is composed of four stages as follows:\n",
    "\n",
    "1. Selection\n",
    "2. Expansion\n",
    "3. Simulation\n",
    "4. Backpropagation\n",
    "\n",
    "The input to the MCTS algorithm is the current state and the output is a probability distribution of all the possible moves. Based on the distribution, we can decide which action to take. This can be just the move with the highest probability.\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/mcts-game.png\" width=\"800\">\n",
    "</center>\n",
    "\n",
    "From the output of the MCTS algorithm, we choose the next action as $6$ since it has the highest probability and it's a winning move for Player 1.\n",
    "\n",
    "The serarch tree is created as follows. We first create a root node with a given state. Then, we follow these steps:\n",
    "\n",
    "1. Check if the current node is fully expanded or not. A node is fully expanded if it has children and no action can be taken.\n",
    "2. If the node is fully expanded, we compute the Upper Confidence Bound (UCB) for each of its children and select the one with the highest UCB.\n",
    "3. Continue the process until you reach a node which is not fully expanded.\n",
    "4. Expand the node and move to the expanded node.\n",
    "5. Run a simulation from the current node to determine if the player is won. Return the reward.\n",
    "6. Run backpropagation to update the reward_sum and visit_count on all the nodes in the path from the node to the root.\n",
    "\n",
    "This process is repeated for a set number of iteration. After that we look at the immediate children of the root node and compute the probability distribution of the visit_counts. We use this distribution to determine the next move.\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/mcts-algorithm.png\" width=\"500\">\n",
    "</center>\n",
    "\n",
    "We use the following formula to compute the UCB of children nodes from a parent node to find out which child to select in the selection step.\n",
    "\n",
    "$$\n",
    "\\frac{v_c}{n_c}+c\\sqrt{\\frac{\\ln n_p}{n_c}},\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "* $n_p$ is the visit count of the parent node $P$,\n",
    "* $n_c$ is the visit count of the child node $C$,\n",
    "* $v_c$ is the total reward (number of wins minus number of losses),\n",
    "* $c$ is the exploration factor.\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/mcts-nodes.png\" width=\"200\">\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"exploration_factor\": 2 ** 0.5,\n",
    "    \"num_iters\": 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self, game, state, params, parent=None, parent_action=None):\n",
    "        self.game = game\n",
    "        self.state = state\n",
    "        self.params = params\n",
    "        self.parent = parent\n",
    "        self.parent_action = parent_action\n",
    "        \n",
    "        self.children = []\n",
    "        self.available_actions = (state[0, :] == 0).astype(np.int8)\n",
    "        \n",
    "        self.reward_sum = 0\n",
    "        self.visit_count = 0\n",
    "        \n",
    "    def expected_reward(self, child):\n",
    "        return -child.reward_sum / child.visit_count\n",
    "        \n",
    "    def ucb(self, child):\n",
    "        '''\n",
    "        Computes the Upper Confidence Bound (UCB).\n",
    "        '''\n",
    "        exploration_factor = self.params[\"exploration_factor\"]\n",
    "        exploration = (np.log(self.visit_count) / child.visit_count) ** 0.5\n",
    "        return self.expected_reward(child) + exploration_factor * exploration   \n",
    "    \n",
    "    def is_fully_expanded(self):\n",
    "        return len(self.children) > 0 and (np.sum(self.available_actions) == 0)\n",
    "    \n",
    "    def select(self):\n",
    "        return max(self.children, key=self.ucb)\n",
    "    \n",
    "    def expand(self):\n",
    "        action = np.random.choice(np.where(self.available_actions == 1)[0])\n",
    "        self.available_actions[action] = 0\n",
    "        \n",
    "        player = self.game.first_player\n",
    "        other_player = self.game.opponent(player)\n",
    "        \n",
    "        child_state = self.game.next_state(self.state.copy(), action, player)\n",
    "        child_state = self.game.neutral_perspective(child_state, other_player)\n",
    "        \n",
    "        child = Node(self.game, child_state, self.params, self, action)\n",
    "        self.children.append(child)\n",
    "        \n",
    "        return child\n",
    "    \n",
    "    def simulate(self):\n",
    "        state = self.state.copy()\n",
    "        parent_action = self.parent_action\n",
    "        player = self.game.first_player\n",
    "        \n",
    "        # while game is not over...\n",
    "        while self.game.is_over(state, parent_action) < 0:\n",
    "            parent_action = np.random.choice(np.where(state[0, :] == 0)[0])\n",
    "            state = self.game.next_state(state, parent_action, player)\n",
    "            player = self.game.opponent(player)\n",
    "        \n",
    "        reward = self.game.is_over(state, parent_action)\n",
    "        # `player` took `parent_action` which resulted in winning `state` so the winner is the\n",
    "        # other player and we need to rever reward.\n",
    "        reward = self.game.opponent_reward(reward)\n",
    "        return reward if player == self.game.first_player else self.game.opponent_reward(reward)\n",
    "    \n",
    "    def backward(self, reward):\n",
    "        \"\"\"\n",
    "        Backpropagate reward and visit counts from the node to the root.\n",
    "        \"\"\"\n",
    "        node = self\n",
    "        while node is not None:\n",
    "            node.reward_sum += reward\n",
    "            node.visit_count += 1\n",
    "            reward = self.game.opponent_reward(reward)\n",
    "            node = node.parent\n",
    "    \n",
    "class MCTS(object):\n",
    "    def __init__(self, game, params):\n",
    "        self.game = game\n",
    "        self.params = params\n",
    "\n",
    "    def best_policy(self, state):\n",
    "        root = Node(self.game, state, self.params)\n",
    "        num_iters = self.params[\"num_iters\"]\n",
    "        \n",
    "        for _ in range(num_iters):\n",
    "            node = self.find_node(root)\n",
    "            reward = node.simulate()\n",
    "            node.backward(reward)\n",
    "\n",
    "        return self.compute_policy(root)\n",
    "  \n",
    "    def find_node(self, root):\n",
    "        node = root\n",
    "\n",
    "        while self.game.is_over(node.state, node.parent_action) < 0:\n",
    "            if not node.is_fully_expanded():\n",
    "                return node.expand()\n",
    "            node = node.select()   \n",
    "\n",
    "        return node\n",
    "    \n",
    "    def compute_policy(self, node):\n",
    "        out = np.zeros(self.game.ncols)\n",
    "        for child in node.children:\n",
    "            out[child.parent_action] = child.visit_count\n",
    "        out /= np.sum(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human-Machine Play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = Connect4()\n",
    "player = game.first_player\n",
    "state = game.init_state()\n",
    "mcts = MCTS(game, params)\n",
    "\n",
    "while True:\n",
    "    print_state(state)\n",
    "    print(f\"player {players[player]} is to play...\")\n",
    "    \n",
    "    available_actions = game.available_actions(state)\n",
    "    print(f\"available actions: {game.available_actions(state)}\")\n",
    "    \n",
    "    if player == game.first_player:\n",
    "        action = int(input(\"provide a valid move: \"))\n",
    "    else:\n",
    "        neutral_state = game.neutral_perspective(state, player)\n",
    "        policy = mcts.best_policy(neutral_state)\n",
    "        action = np.argmax(policy)        \n",
    "\n",
    "        plt.bar(range(len(policy)), policy)\n",
    "        plt.show()\n",
    "    \n",
    "    state = game.next_state(state, action, player)\n",
    "\n",
    "    is_over = game.is_over(state, action)\n",
    "    if is_over >= 0:\n",
    "        print_state(state)\n",
    "        if is_over == 0:\n",
    "            print(\"draw!\")\n",
    "        else:\n",
    "            print(f\"player {players[player]} won!\")\n",
    "        break\n",
    "        \n",
    "    player = game.opponent(player)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine-Machine PLay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = Connect4()\n",
    "player = game.first_player\n",
    "state = game.init_state()\n",
    "mcts = MCTS(game, params)\n",
    "\n",
    "while True:\n",
    "    print_state(state)\n",
    "    print(f\"player {players[player]} is to play...\")\n",
    "    \n",
    "    available_actions = game.available_actions(state)\n",
    "    print(f\"available actions: {game.available_actions(state)}\")\n",
    "    \n",
    "    neutral_state = game.neutral_perspective(state, player)\n",
    "    policy = mcts.best_policy(neutral_state)\n",
    "    action = np.argmax(policy)        \n",
    "\n",
    "    # plt.bar(range(len(policy)), policy)\n",
    "    # plt.show()\n",
    "    \n",
    "    state = game.next_state(state, action, player)\n",
    "\n",
    "    is_over = game.is_over(state, action)\n",
    "    if is_over >= 0:\n",
    "        print_state(state)\n",
    "        if is_over == 0:\n",
    "            print(\"draw!\")\n",
    "        else:\n",
    "            print(f\"player {players[player]} won!\")\n",
    "        break\n",
    "        \n",
    "    player = game.opponent(player)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCTS with Neural Networks\n",
    "\n",
    "In this approach, we build a convolutional neural network (CNN) to predict policy and reward given a state. To train such a model, we use MCTS with slight modifications. We remove the simulation step and use an untrained CNN. Like the simulation, the untrained model plays randomly to generate training data.\n",
    "\n",
    "We modify the tree search by replacing the simulation step with a neural network which returns a policy and a reward for a given state. The serarch tree is created as follows. We first create a root node with a given state. Then, we follow these steps:\n",
    "\n",
    "1. As long as the node has children, compute the Upper Confidence Bound (UCB) for each of its children and select the one with the highest UCB. Repeat this until you reach a leaf node.\n",
    "2. Given the current node state, run a convolutional neural network (CNN) to get the policy and reward.\n",
    "3. Fully expand this leaf node using the policy.\n",
    "4. Using the reward, run the backpropagation to update the reward_sum and visit_count on all the nodes in the path from the node to the root.\n",
    "\n",
    "This process is repeated for a set number of iteration. After that we look at the immediate children of the root node and compute the probability distribution of the visit_counts. We use this distribution to determine the next move.\n",
    "\n",
    "Using this MCTS approach, we generate enough training and validation dataset for model training. Then, we train our CNN model. Once the model is trained it can be used for playing actual games.\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/mcts-cnn-algorithm.png\" width=\"500\">\n",
    "</center>\n",
    "\n",
    "We use the following formula to compute the UCB of children nodes from a parent node to find out which child to select in the selection step.\n",
    "\n",
    "$$\n",
    "\\frac{v_c}{n_c}+cp_c\\frac{\\sqrt{n_p}}{1 + n_c},\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "* $n_p$ is the visit count of the parent node $P$,\n",
    "* $n_c$ is the visit count of the child node $C$,\n",
    "* $v_c$ is the total reward (number of wins minus number of losses),\n",
    "* $p_c$ is the prior probability provided by the policy from the CNN model for the child node state, \n",
    "* $c$ is the exploration factor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model\n",
    "\n",
    "We build a CNN model that learns the following function which maps a state $S$ to a policy-reward pair $(P, R)$:\n",
    "\n",
    "$$\n",
    "f(S) = (P, R).\n",
    "$$\n",
    "\n",
    "The policy $P$ is a probability distribution of all possible next states from $S$ and $v$ is reward in $(-1, 1)$ which is interpreted as reward. Rewards close to $1$ indicates winning, while rewards close to $-1$ indicates losing. The rewards close to $0$ is interpreted as a drawish situation.\n",
    "\n",
    "We interpret a state as an image in the CNN model. We use one-hot encoding for possible values $\\{-1, 0, 1\\}$ of each cell in a given state. So, let's define:\n",
    "\n",
    "* $-1$: $[1, 0 ,0]$\n",
    "* $\\phantom{-}0$: $[0, 1 ,0]$\n",
    "* $\\phantom{-}1$: $[0, 0 ,1]$\n",
    "\n",
    "As a result, we have a 3D input of size $3\\times 6\\times 7$ for a given state.\n",
    "\n",
    "Then, we build multiple convolutional layers followed by two head as follows:\n",
    "\n",
    "* **Policy Head:** The output layer size in this head is the number of possible next states. We apply softmax on the output layer to obtain a probability distribution which can be used to decide the next move.\n",
    "* **Reward Head:** the output layer size in this head is one. We apply `Tanh` activation function to get a reward in $(-1, 1)$ representing a reward for the input state $S$. The reward is the model evaluation of a given state.\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/connect4-cnn-model.png\" width=800>\n",
    "</center>\n",
    "\n",
    "As we can see, we encode the current state and feed into the ResNet model which consists of multiple blocks arranged sequentially. A single block of the ResNet model consists of convolutional and batch normalization layers and ReLU activations as follows. Note that a skip connection is also added to the block.\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/resnet-block.png\" width=200>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm.notebook import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # CNN Model parameters\n",
    "    \"kernel_size\": 3,\n",
    "    \"padding\": 1,\n",
    "    \"embd_size\": 3,\n",
    "    \"hidden_size\": 128,\n",
    "    \"num_blocks\": 8,\n",
    "    \"dropout\": 0.1,\n",
    "    # MCTS parameters\n",
    "    \"num_simulations\": 100,\n",
    "    \"exploration_factor\": 2,\n",
    "    \"dirichlet_epsilon\": 0.25,\n",
    "    \"dirichlet_alpha\": 0.3,\n",
    "    # AlphaZero parameters\n",
    "    \"num_training_cycles\": 2,\n",
    "    \"num_self_plays\": 10,\n",
    "    \"num_epochs\": 100,\n",
    "    \"batch_size\": 16,\n",
    "    \"train_ratio\": 0.9,\n",
    "    # Training settings\n",
    "    \"load_model\": False,\n",
    "    # Plotting paramaters\n",
    "    \"loss_eval_size\": 10,\n",
    "    # Optimizer parameters\n",
    "    \"lr\": 0.2,\n",
    "    \"weight_decay\": 0.1,\n",
    "    # General parameters\n",
    "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we build a convolutional neural network (CNN) which we descibed earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, hidden_size, params):\n",
    "        super().__init__()\n",
    "\n",
    "        kernel_size = params[\"kernel_size\"]\n",
    "        padding = params[\"padding\"]\n",
    "        dropout = params[\"dropout\"]\n",
    "\n",
    "        self.res_block = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                hidden_size, hidden_size, kernel_size=kernel_size, padding=padding\n",
    "            ),\n",
    "            nn.BatchNorm2d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                hidden_size, hidden_size, kernel_size=kernel_size, padding=padding\n",
    "            ),\n",
    "            nn.BatchNorm2d(hidden_size),\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x + self.res_block(x)\n",
    "        out = F.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, game, embd_size, hidden_size, num_blocks, params):\n",
    "        super().__init__()\n",
    "\n",
    "        kernel_size = params[\"kernel_size\"]\n",
    "        padding = params[\"padding\"]\n",
    "        dropout = params[\"dropout\"]\n",
    "\n",
    "        self.start_block = nn.Sequential(\n",
    "            nn.Conv2d(embd_size, hidden_size, kernel_size=kernel_size, padding=padding),\n",
    "            nn.BatchNorm2d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "        self.res_blocks = nn.ModuleList(\n",
    "            [ResBlock(hidden_size, params) for _ in range(num_blocks)]\n",
    "        )\n",
    "\n",
    "        self.policy_head = nn.Sequential(\n",
    "            nn.Conv2d(hidden_size, embd_size, kernel_size=kernel_size, padding=padding),\n",
    "            nn.BatchNorm2d(embd_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(embd_size * game.nrows * game.ncols, game.ncols),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "        self.reward_head = nn.Sequential(\n",
    "            nn.Conv2d(hidden_size, embd_size, kernel_size=kernel_size, padding=padding),\n",
    "            nn.BatchNorm2d(embd_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(embd_size * game.nrows * game.ncols, 1),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.start_block(x)\n",
    "\n",
    "        for res_block in self.res_blocks:\n",
    "            out = res_block(out)\n",
    "\n",
    "        logit = self.policy_head(out)\n",
    "        reward = self.reward_head(out)\n",
    "\n",
    "        return logit, reward\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function encodes a $6\\times 7$ state of a Connect4 game into a $3\\times 6\\times 7$ array, in which the first dimension if the embedding size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_state(state):\n",
    "    \"\"\"\n",
    "    m, n = state.shape\n",
    "    output size: 3 x m x n\n",
    "    \"\"\"\n",
    "    return np.stack([state == 1, state == 0, state == -1]).astype(np.float32)\n",
    "\n",
    "\n",
    "def decode_state(enc_state):\n",
    "    return 1 * enc_state[0] + 0 * enc_state[1] + (-1) * enc_state[2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now design an MCTS class which implements the tree search. Starting from a root node, the algorithm select a child if the current node is fully expanded. If not, the algorithm fully expands it to all possible states.\n",
    "\n",
    "We replace the simulation part of the MCTS with an untrained CNN model. Thus, the algorithm plays randomly for a set number of iterations and records states, policies, and rewards as training dataset.\n",
    "\n",
    "Using the training dataset from random plays, we will train a CNN model. The trained model can then be used for actual playing without a need for MCTS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(\n",
    "        self, game, state, params, parent=None, parent_action=None, prior_prob=0, visit_count=0\n",
    "    ):\n",
    "        self.game = game\n",
    "        self.state = state\n",
    "        self.params = params\n",
    "        self.parent = parent\n",
    "        self.parent_action = parent_action\n",
    "\n",
    "        self.children = []\n",
    "\n",
    "        self.reward_sum = 0\n",
    "        self.visit_count = visit_count\n",
    "        self.prior_prob = prior_prob\n",
    "\n",
    "    def expected_reward(self, child):\n",
    "        if child.visit_count == 0:\n",
    "            return 0\n",
    "        return -child.reward_sum / child.visit_count\n",
    "\n",
    "    def ucb(self, child):\n",
    "        \"\"\"\n",
    "        Computes the Upper Confidence Bound (UCB).\n",
    "        \"\"\"\n",
    "        exploration_factor = self.params[\"exploration_factor\"]\n",
    "        exploration = (self.visit_count) ** 0.5 / (1 + child.visit_count)\n",
    "        return (\n",
    "            self.expected_reward(child)\n",
    "            + exploration_factor * child.prior_prob * exploration\n",
    "        )\n",
    "\n",
    "    def is_fully_expanded(self):\n",
    "        return len(self.children) > 0\n",
    "\n",
    "    def select(self):\n",
    "        return max(self.children, key=self.ucb)\n",
    "\n",
    "    def expand(self, policy):\n",
    "        for action, prob in enumerate(policy):\n",
    "            if prob == 0:\n",
    "                continue\n",
    "\n",
    "            player = self.game.first_player\n",
    "            other_player = self.game.opponent(player)\n",
    "\n",
    "            child_state = self.game.next_state(self.state.copy(), action, player)\n",
    "            child_state = self.game.neutral_perspective(child_state, other_player)\n",
    "\n",
    "            child = Node(self.game, child_state, self.params, self, action, prob)\n",
    "            self.children.append(child)\n",
    "\n",
    "    def backward(self, reward):\n",
    "        \"\"\"\n",
    "        Backpropagate reward and visit counts from the node to the root.\n",
    "        \"\"\"\n",
    "        self.reward_sum += reward\n",
    "        self.visit_count += 1\n",
    "        # parent node is the opponent of the child node.\n",
    "        reward = self.game.opponent_reward(reward)\n",
    "        if self.parent is not None:\n",
    "            self.parent.backward(reward)\n",
    "\n",
    "\n",
    "class MCTS(object):\n",
    "    def __init__(self, params):\n",
    "        self.game = Connect4()\n",
    "\n",
    "        embd_size = params[\"embd_size\"]\n",
    "        hidden_size = params[\"hidden_size\"]\n",
    "        num_blocks = params[\"num_blocks\"]\n",
    "        device = params[\"device\"]\n",
    "        self.model = ResNet(self.game, embd_size, hidden_size, num_blocks, params).to(\n",
    "            device\n",
    "        )\n",
    "\n",
    "        self.params = params\n",
    "\n",
    "    def policy_reward(self, state):\n",
    "        enc_state = encode_state(state)\n",
    "        enc_state = torch.tensor(enc_state, device=self.params[\"device\"]).unsqueeze(0)\n",
    "\n",
    "        logit, reward = self.model(enc_state)\n",
    "        reward = reward.item()\n",
    "        # mask out illegal moves\n",
    "        logit[:, state[0, :] != 0] = -np.inf\n",
    "        policy = F.softmax(logit, dim=1).squeeze(0).detach().cpu().numpy()\n",
    "\n",
    "        return policy, reward\n",
    "\n",
    "    def dirichlet_policy(self, policy, state):\n",
    "        eps, alpha = params[\"dirichlet_epsilon\"], params[\"dirichlet_alpha\"]\n",
    "        dirichlet_noise = np.random.dirichlet([alpha] * len(policy))\n",
    "        policy = (1 - eps) * policy + eps * dirichlet_noise\n",
    "        # mask out illegal moves\n",
    "        policy[state[0, :] != 0] = 0\n",
    "        policy /= np.sum(policy)\n",
    "        return policy\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def best_policy(self, state):\n",
    "        policy, _ = self.policy_reward(state)\n",
    "        policy = self.dirichlet_policy(policy, state)\n",
    "\n",
    "        root = Node(self.game, state, self.params, visit_count=1)\n",
    "        root.expand(policy)\n",
    "\n",
    "        num_simulations = self.params[\"num_simulations\"]\n",
    "\n",
    "        for _ in range(num_simulations):\n",
    "            node = root\n",
    "\n",
    "            while node.is_fully_expanded():\n",
    "                node = node.select()\n",
    "\n",
    "            is_over = self.game.is_over(node.state, node.parent_action)\n",
    "            # check if it's not over.\n",
    "            if is_over < 0:\n",
    "                policy, reward = self.policy_reward(node.state)\n",
    "                node.expand(policy)\n",
    "            else:\n",
    "                # 0 for draw and 1 for win\n",
    "                reward = is_over\n",
    "                reward = self.game.opponent_reward(reward)\n",
    "\n",
    "            node.backward(reward)\n",
    "\n",
    "        return self.compute_policy(root)\n",
    "\n",
    "    def compute_policy(self, root):\n",
    "        out = np.zeros(self.game.ncols)\n",
    "\n",
    "        for child in root.children:\n",
    "            out[child.parent_action] = child.visit_count\n",
    "\n",
    "        out /= np.sum(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we define AlphaZero class, which implements:\n",
    "\n",
    "* Training data generation through self-play.\n",
    "* Model training using the training data.\n",
    "* Repeating above two steps to refine the model.\n",
    "\n",
    "We generate multiple training dataset from a single self-play. The algorithm plays randomly against itself until a player wins or it's a draw.\n",
    "\n",
    "As an example, suppose Player $1$ starts the game and Player $-1$ wins after $6$ moves. We record $\\{(S_i, P_i, R_i)\\mid i=0,\\ldots,6\\}$, where $S_i$ and $P_i$ are the state and policy at move $i$ and $R_i$ is the reward assigned for each move once the game is over. In this particular case, since Player $-1$ won after $6$ moves, we have:\n",
    "\n",
    "$$\n",
    "R = [-1, 1, -1, 1, -1, 1].\n",
    "$$\n",
    "\n",
    "We can repeat this generation process by many self-plays to generate more training and validation datasets.\n",
    "\n",
    "We now define two functions for training and evaluating data. For a number of epochs, we feed in the encoded states in batches to the model to obtain predicted policies and rewards for the batch. We then compute the losses for both policies and rewards. We optimize model parameters to minimize both losses.\n",
    "\n",
    "At every training cycle, we evaluate the updated model against the evaluation dataset. We save the model at the end of each training cycle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To organize training and evaluation losses for the policy and reward, we define the following classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(object):\n",
    "    def __init__(self):\n",
    "        self.train = []\n",
    "        self.eval = []\n",
    "\n",
    "\n",
    "class Losses(object):\n",
    "    def __init__(self):\n",
    "        self.policy = Loss()\n",
    "        self.reward = Loss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaZero(object):\n",
    "    def __init__(self, params):\n",
    "        self.mcts = MCTS(params)\n",
    "\n",
    "        lr = params[\"lr\"]\n",
    "        weight_decay = params[\"weight_decay\"]\n",
    "        self.optimizer = torch.optim.Adam(\n",
    "            self.mcts.model.parameters(), lr=lr, weight_decay=weight_decay\n",
    "        )\n",
    "\n",
    "        self.params = params\n",
    "\n",
    "    def generate_dataset(self, num_self_plays, data=None):\n",
    "        if data is None:\n",
    "            states, policies, rewards = [], [], []\n",
    "        else:\n",
    "            states, policies, rewards = data\n",
    "\n",
    "        for _ in trange(num_self_plays):\n",
    "            s, p, r = self.generate_data()\n",
    "            states.extend(s)\n",
    "            policies.extend(p)\n",
    "            rewards.extend(r)\n",
    "\n",
    "        return states, policies, rewards\n",
    "\n",
    "    def generate_data(self):\n",
    "        game = self.mcts.game\n",
    "        player = game.first_player\n",
    "        state = game.init_state()\n",
    "\n",
    "        reward = 0\n",
    "        states, policies, players = [], [], []\n",
    "\n",
    "        while True:\n",
    "            players.append(player)\n",
    "\n",
    "            neutral_state = game.neutral_perspective(state, player)\n",
    "            states.append(encode_state(neutral_state))\n",
    "\n",
    "            policy = self.mcts.best_policy(neutral_state)\n",
    "            policies.append(policy)\n",
    "\n",
    "            action = np.random.choice(len(policy), p=policy)\n",
    "            state = game.next_state(state, action, player)\n",
    "\n",
    "            is_over = game.is_over(state, action)\n",
    "            if is_over >= 0:\n",
    "                reward = is_over\n",
    "                break\n",
    "\n",
    "            player = game.opponent(player)\n",
    "\n",
    "        rewards = [\n",
    "            reward if p == player else game.opponent_reward(reward) for p in players\n",
    "        ]\n",
    "\n",
    "        return states, policies, rewards\n",
    "\n",
    "    def train_model(self, train_data, eval_data, losses=None):\n",
    "        if losses is None:\n",
    "            losses = Losses()\n",
    "\n",
    "        states, policies, rewards = train_data\n",
    "        num_epochs = self.params[\"num_epochs\"]\n",
    "        batch_size = self.params[\"batch_size\"]\n",
    "        device = self.params[\"device\"]\n",
    "\n",
    "        for _ in trange(num_epochs):\n",
    "            self.mcts.model.train()\n",
    "            batch_indices = np.random.choice(len(states), batch_size, replace=False)\n",
    "\n",
    "            enc_states = torch.tensor(\n",
    "                states[batch_indices], dtype=torch.float32, device=device\n",
    "            )\n",
    "            target_policies = torch.tensor(\n",
    "                policies[batch_indices], dtype=torch.float32, device=device\n",
    "            )\n",
    "            target_rewards = torch.tensor(\n",
    "                rewards[batch_indices], dtype=torch.float32, device=device\n",
    "            ).unsqueeze(1)\n",
    "\n",
    "            pred_logits, pred_rewards = self.mcts.model(enc_states)\n",
    "\n",
    "            pred_policies = F.softmax(pred_logits, dim=1)\n",
    "            policy_loss = F.cross_entropy(pred_policies, target_policies)\n",
    "            reward_loss = F.mse_loss(pred_rewards, target_rewards)\n",
    "\n",
    "            losses.policy.train.append(policy_loss.item())\n",
    "            losses.reward.train.append(reward_loss.item())\n",
    "\n",
    "            self.optimizer.zero_grad(set_to_none=True)\n",
    "            policy_loss.backward(retain_graph=True)\n",
    "            reward_loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            self.mcts.model.eval()\n",
    "            policy_loss, reward_loss = self.eval_model(eval_data)\n",
    "            losses.policy.eval.append(policy_loss.item())\n",
    "            losses.reward.eval.append(reward_loss.item())\n",
    "\n",
    "        return losses\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def eval_model(self, eval_data):\n",
    "        device = self.params[\"device\"]\n",
    "\n",
    "        states, policies, rewards = eval_data\n",
    "        states, policies, rewards = (\n",
    "            np.array(states),\n",
    "            np.array(policies),\n",
    "            np.array(rewards),\n",
    "        )\n",
    "\n",
    "        enc_states = torch.tensor(states, dtype=torch.float32, device=device)\n",
    "        target_policies = torch.tensor(policies, dtype=torch.float32, device=device)\n",
    "        target_rewards = torch.tensor(\n",
    "            rewards, dtype=torch.float32, device=device\n",
    "        ).unsqueeze(1)\n",
    "\n",
    "        pred_logits, pred_rewards = self.mcts.model(enc_states)\n",
    "\n",
    "        pred_policies = F.softmax(pred_logits, dim=1)\n",
    "        policy_loss = F.cross_entropy(pred_policies, target_policies)\n",
    "        reward_loss = F.mse_loss(pred_rewards, target_rewards)\n",
    "\n",
    "        return policy_loss, reward_loss\n",
    "\n",
    "    def split(self, data):\n",
    "        states, policies, rewards = data\n",
    "        states, policies, rewards = (\n",
    "            np.array(states),\n",
    "            np.array(policies),\n",
    "            np.array(rewards),\n",
    "        )\n",
    "        num_records = len(states)\n",
    "        train_ratio = params[\"train_ratio\"]\n",
    "        train_size = int(train_ratio * num_records)\n",
    "\n",
    "        idx = np.random.choice(num_records, num_records, replace=False)\n",
    "        train_idx, eval_idx = idx[:train_size], idx[train_size:]\n",
    "\n",
    "        train_data = states[train_idx], policies[train_idx], rewards[train_idx]\n",
    "        eval_data = states[eval_idx], policies[eval_idx], rewards[eval_idx]\n",
    "\n",
    "        return train_data, eval_data\n",
    "\n",
    "    def learn(self):\n",
    "        num_training_cycles = params[\"num_training_cycles\"]\n",
    "        num_self_plays = params[\"num_self_plays\"]\n",
    "        losses = None\n",
    "\n",
    "        for training_cycle in trange(num_training_cycles):\n",
    "            data = self.generate_dataset(num_self_plays)\n",
    "            train_data, eval_data = self.split(data)\n",
    "\n",
    "            losses = self.train_model(train_data, eval_data, losses)\n",
    "\n",
    "            model_checkpoint = {\n",
    "                \"model\": self.mcts.model.state_dict(),\n",
    "                \"optimizer\": self.optimizer.state_dict(),\n",
    "            }\n",
    "            model_location = f\"./models/model_{self.mcts.game}_{training_cycle}.pt\"\n",
    "\n",
    "            torch.save(model_checkpoint, model_location)\n",
    "\n",
    "        torch.save(model_checkpoint, f\"./models/model_{self.mcts.game}_latest.pt\")\n",
    "\n",
    "        losses_location = f\"./data/losses_{self.mcts.game}.pt\"\n",
    "        torch.save(losses, losses_location)\n",
    "\n",
    "        return losses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trained Model Against Untrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a755d7880c24ac7ae3a0a56bcf62c29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94617abefecd44e285f05e736373c885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc86156ad35e443db77b47ce8450101f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f82b86d5f574b4daba2df90ca58355f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91037da8bed44833a2744b11a94c6e7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48e8265afd8443a8b26c3335dd24fcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e12a9dc9531d42998923be4b9a458092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  .  .  .\n",
      "\n",
      "available actions: [0 1 2 3 4 5 6]\n",
      "player B move: 4\n",
      "\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  B  .  .\n",
      "\n",
      "available actions: [0 1 2 3 4 5 6]\n",
      "player R move: 1\n",
      "\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  R  .  .  B  .  .\n",
      "\n",
      "available actions: [0 1 2 3 4 5 6]\n",
      "player B move: 3\n",
      "\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  R  .  B  B  .  .\n",
      "\n",
      "available actions: [0 1 2 3 4 5 6]\n",
      "player R move: 3\n",
      "\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  R  .  .  .\n",
      "\t.  R  .  B  B  .  .\n",
      "\n",
      "available actions: [0 1 2 3 4 5 6]\n",
      "player B move: 4\n",
      "\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  R  B  .  .\n",
      "\t.  R  .  B  B  .  .\n",
      "\n",
      "available actions: [0 1 2 3 4 5 6]\n",
      "player R move: 2\n",
      "\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  R  B  .  .\n",
      "\t.  R  R  B  B  .  .\n",
      "\n",
      "available actions: [0 1 2 3 4 5 6]\n",
      "player B move: 4\n",
      "\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  B  .  .\n",
      "\t.  .  .  R  B  .  .\n",
      "\t.  R  R  B  B  .  .\n",
      "\n",
      "available actions: [0 1 2 3 4 5 6]\n",
      "player R move: 4\n",
      "\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  R  .  .\n",
      "\t.  .  .  .  B  .  .\n",
      "\t.  .  .  R  B  .  .\n",
      "\t.  R  R  B  B  .  .\n",
      "\n",
      "available actions: [0 1 2 3 4 5 6]\n",
      "player B move: 6\n",
      "\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  R  .  .\n",
      "\t.  .  .  .  B  .  .\n",
      "\t.  .  .  R  B  .  .\n",
      "\t.  R  R  B  B  .  B\n",
      "\n",
      "available actions: [0 1 2 3 4 5 6]\n",
      "player R move: 5\n",
      "\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  R  .  .\n",
      "\t.  .  .  .  B  .  .\n",
      "\t.  .  .  R  B  .  .\n",
      "\t.  R  R  B  B  R  B\n",
      "\n",
      "available actions: [0 1 2 3 4 5 6]\n",
      "player B move: 1\n",
      "\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  R  .  .\n",
      "\t.  .  .  .  B  .  .\n",
      "\t.  B  .  R  B  .  .\n",
      "\t.  R  R  B  B  R  B\n",
      "\n",
      "available actions: [0 1 2 3 4 5 6]\n",
      "player R move: 3\n",
      "\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  R  .  .\n",
      "\t.  .  .  R  B  .  .\n",
      "\t.  B  .  R  B  .  .\n",
      "\t.  R  R  B  B  R  B\n",
      "\n",
      "available actions: [0 1 2 3 4 5 6]\n",
      "player B move: 2\n",
      "\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  R  .  .\n",
      "\t.  .  .  R  B  .  .\n",
      "\t.  B  B  R  B  .  .\n",
      "\t.  R  R  B  B  R  B\n",
      "\n",
      "available actions: [0 1 2 3 4 5 6]\n",
      "player R move: 6\n",
      "\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  R  .  .\n",
      "\t.  .  .  R  B  .  .\n",
      "\t.  B  B  R  B  .  R\n",
      "\t.  R  R  B  B  R  B\n",
      "\n",
      "available actions: [0 1 2 3 4 5 6]\n",
      "player B move: 0\n",
      "\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  R  .  .\n",
      "\t.  .  .  R  B  .  .\n",
      "\t.  B  B  R  B  .  R\n",
      "\tB  R  R  B  B  R  B\n",
      "\n",
      "available actions: [0 1 2 3 4 5 6]\n",
      "player R move: 5\n",
      "\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  R  .  .\n",
      "\t.  .  .  R  B  .  .\n",
      "\t.  B  B  R  B  R  R\n",
      "\tB  R  R  B  B  R  B\n",
      "\n",
      "available actions: [0 1 2 3 4 5 6]\n",
      "player B move: 4\n",
      "\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  B  .  .\n",
      "\t.  .  .  .  R  .  .\n",
      "\t.  .  .  R  B  .  .\n",
      "\t.  B  B  R  B  R  R\n",
      "\tB  R  R  B  B  R  B\n",
      "\n",
      "available actions: [0 1 2 3 4 5 6]\n",
      "player R move: 0\n",
      "\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  B  .  .\n",
      "\t.  .  .  .  R  .  .\n",
      "\t.  .  .  R  B  .  .\n",
      "\tR  B  B  R  B  R  R\n",
      "\tB  R  R  B  B  R  B\n",
      "\n",
      "available actions: [0 1 2 3 4 5 6]\n",
      "player B move: 2\n",
      "\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  B  .  .\n",
      "\t.  .  .  .  R  .  .\n",
      "\t.  .  B  R  B  .  .\n",
      "\tR  B  B  R  B  R  R\n",
      "\tB  R  R  B  B  R  B\n",
      "\n",
      "available actions: [0 1 2 3 4 5 6]\n",
      "player R move: 3\n",
      "\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  .  B  .  .\n",
      "\t.  .  .  R  R  .  .\n",
      "\t.  .  B  R  B  .  .\n",
      "\tR  B  B  R  B  R  R\n",
      "\tB  R  R  B  B  R  B\n",
      "\n",
      "available actions: [0 1 2 3 4 5 6]\n",
      "player B move: 3\n",
      "\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  B  B  .  .\n",
      "\t.  .  .  R  R  .  .\n",
      "\t.  .  B  R  B  .  .\n",
      "\tR  B  B  R  B  R  R\n",
      "\tB  R  R  B  B  R  B\n",
      "\n",
      "available actions: [0 1 2 3 4 5 6]\n",
      "player R move: 2\n",
      "\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  B  B  .  .\n",
      "\t.  .  R  R  R  .  .\n",
      "\t.  .  B  R  B  .  .\n",
      "\tR  B  B  R  B  R  R\n",
      "\tB  R  R  B  B  R  B\n",
      "\n",
      "available actions: [0 1 2 3 4 5 6]\n",
      "player B move: 0\n",
      "\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  B  B  .  .\n",
      "\t.  .  R  R  R  .  .\n",
      "\tB  .  B  R  B  .  .\n",
      "\tR  B  B  R  B  R  R\n",
      "\tB  R  R  B  B  R  B\n",
      "\n",
      "available actions: [0 1 2 3 4 5 6]\n",
      "player R move: 5\n",
      "\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  B  B  .  .\n",
      "\t.  .  R  R  R  .  .\n",
      "\tB  .  B  R  B  R  .\n",
      "\tR  B  B  R  B  R  R\n",
      "\tB  R  R  B  B  R  B\n",
      "\n",
      "available actions: [0 1 2 3 4 5 6]\n",
      "player B move: 5\n",
      "\n",
      "\t.  .  .  .  .  .  .\n",
      "\t.  .  .  B  B  .  .\n",
      "\t.  .  R  R  R  B  .\n",
      "\tB  .  B  R  B  R  .\n",
      "\tR  B  B  R  B  R  R\n",
      "\tB  R  R  B  B  R  B\n",
      "\n",
      "available actions: [0 1 2 3 4 5 6]\n",
      "player R move: 3\n",
      "\n",
      "\t.  .  .  R  .  .  .\n",
      "\t.  .  .  B  B  .  .\n",
      "\t.  .  R  R  R  B  .\n",
      "\tB  .  B  R  B  R  .\n",
      "\tR  B  B  R  B  R  R\n",
      "\tB  R  R  B  B  R  B\n",
      "\n",
      "available actions: [0 1 2 4 5 6]\n",
      "player B move: 0\n",
      "\n",
      "\t.  .  .  R  .  .  .\n",
      "\t.  .  .  B  B  .  .\n",
      "\tB  .  R  R  R  B  .\n",
      "\tB  .  B  R  B  R  .\n",
      "\tR  B  B  R  B  R  R\n",
      "\tB  R  R  B  B  R  B\n",
      "\n",
      "available actions: [0 1 2 4 5 6]\n",
      "player R move: 1\n",
      "\n",
      "\t.  .  .  R  .  .  .\n",
      "\t.  .  .  B  B  .  .\n",
      "\tB  .  R  R  R  B  .\n",
      "\tB  R  B  R  B  R  .\n",
      "\tR  B  B  R  B  R  R\n",
      "\tB  R  R  B  B  R  B\n",
      "\n",
      "available actions: [0 1 2 4 5 6]\n",
      "player B move: 1\n",
      "\n",
      "\t.  .  .  R  .  .  .\n",
      "\t.  .  .  B  B  .  .\n",
      "\tB  B  R  R  R  B  .\n",
      "\tB  R  B  R  B  R  .\n",
      "\tR  B  B  R  B  R  R\n",
      "\tB  R  R  B  B  R  B\n",
      "\n",
      "available actions: [0 1 2 4 5 6]\n",
      "player R move: 0\n",
      "\n",
      "\t.  .  .  R  .  .  .\n",
      "\tR  .  .  B  B  .  .\n",
      "\tB  B  R  R  R  B  .\n",
      "\tB  R  B  R  B  R  .\n",
      "\tR  B  B  R  B  R  R\n",
      "\tB  R  R  B  B  R  B\n",
      "\n",
      "available actions: [0 1 2 4 5 6]\n",
      "player B move: 2\n",
      "\n",
      "\t.  .  .  R  .  .  .\n",
      "\tR  .  B  B  B  .  .\n",
      "\tB  B  R  R  R  B  .\n",
      "\tB  R  B  R  B  R  .\n",
      "\tR  B  B  R  B  R  R\n",
      "\tB  R  R  B  B  R  B\n",
      "\n",
      "available actions: [0 1 2 4 5 6]\n",
      "player R move: 1\n",
      "\n",
      "\t.  .  .  R  .  .  .\n",
      "\tR  R  B  B  B  .  .\n",
      "\tB  B  R  R  R  B  .\n",
      "\tB  R  B  R  B  R  .\n",
      "\tR  B  B  R  B  R  R\n",
      "\tB  R  R  B  B  R  B\n",
      "\n",
      "available actions: [0 1 2 4 5 6]\n",
      "player B move: 5\n",
      "\n",
      "\t.  .  .  R  .  .  .\n",
      "\tR  R  B  B  B  B  .\n",
      "\tB  B  R  R  R  B  .\n",
      "\tB  R  B  R  B  R  .\n",
      "\tR  B  B  R  B  R  R\n",
      "\tB  R  R  B  B  R  B\n",
      "\n",
      "player B won!\n"
     ]
    }
   ],
   "source": [
    "alpha0 = AlphaZero(params)\n",
    "\n",
    "game = alpha0.mcts.game\n",
    "player = game.first_player\n",
    "state = game.init_state()\n",
    "\n",
    "if params[\"load_model\"]:\n",
    "    model_checkpoint = torch.load(f\"./models/model_{game}_latest.pt\")\n",
    "    alpha0.mcts.model.load_state_dict(model_checkpoint[\"model\"])\n",
    "    alpha0.optimizer.load_state_dict(model_checkpoint[\"optimizer\"])\n",
    "else:\n",
    "    losses = alpha0.learn()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(2)\n",
    "    loss_eval_size = params[\"loss_eval_size\"]\n",
    "\n",
    "    ax1.plot(\n",
    "        torch.tensor(losses.policy.train).view(-1, loss_eval_size).mean(axis=1)\n",
    "    )\n",
    "    ax1.plot(torch.tensor(losses.policy.eval).view(-1, loss_eval_size).mean(axis=1))\n",
    "    ax1.legend([\"training policy loss\", \"evaluation policy loss\"])\n",
    "    ax1.grid()\n",
    "\n",
    "    ax2.plot(\n",
    "        torch.tensor(losses.reward.train).view(-1, loss_eval_size).mean(axis=1)\n",
    "    )\n",
    "    ax2.plot(torch.tensor(losses.reward.eval).view(-1, loss_eval_size).mean(axis=1))\n",
    "    ax2.legend([\"training reward loss\", \"evaluation reward loss\"])\n",
    "    ax2.grid()\n",
    "\n",
    "    plt.savefig(\"./images/loss.png\")\n",
    "    plt.show()\n",
    "\n",
    "untrained_mcts = MCTS(params)\n",
    "\n",
    "while True:\n",
    "    print_state(state)\n",
    "\n",
    "    available_actions = game.available_actions(state)\n",
    "    print(f\"available actions: {game.available_actions(state)}\")\n",
    "\n",
    "    neutral_state = game.neutral_perspective(state, player)\n",
    "\n",
    "    if player == game.first_player:\n",
    "        policy = untrained_mcts.best_policy(neutral_state)\n",
    "    else:\n",
    "        policy = alpha0.mcts.best_policy(neutral_state)\n",
    "\n",
    "    action = np.argmax(policy)\n",
    "    print(f\"player {players[player]} move: {action}\")\n",
    "\n",
    "    state = game.next_state(state, action, player)\n",
    "\n",
    "    is_over = game.is_over(state, action)\n",
    "    if is_over >= 0:\n",
    "        print_state(state)\n",
    "        if is_over == 0:\n",
    "            print(\"draw!\")\n",
    "        else:\n",
    "            print(f\"player {players[player]} won!\")\n",
    "        break\n",
    "\n",
    "    player = game.opponent(player)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_model_test(model, enc_state):\n",
    "    model.eval()\n",
    "\n",
    "    policy, reward = model(enc_state)\n",
    "    policy = F.softmax(policy, dim=1).squeeze(0).detach().cpu().numpy()\n",
    "\n",
    "    print(f\"\\treward: {reward.item()}\")\n",
    "    print(\"\\tpolicy bar plot:\")\n",
    "    plt.bar(range(len(policy)), policy)\n",
    "    plt.show()\n",
    "    \n",
    "game = Connect4()\n",
    "\n",
    "embd_size = params[\"embd_size\"]\n",
    "hidden_size = params[\"hidden_size\"]\n",
    "num_blocks = params[\"num_blocks\"]\n",
    "device = params[\"device\"]\n",
    "\n",
    "state = game.init_state()\n",
    "state = game.next_state(state, 2, 1)\n",
    "state = game.next_state(state, 2, -1)\n",
    "state = game.next_state(state, 4, 1)\n",
    "state = game.next_state(state, 3, -1)\n",
    "state = game.next_state(state, 3, 1)\n",
    "state = game.next_state(state, 4, -1)\n",
    "state = game.next_state(state, 4, 1)\n",
    "state = game.next_state(state, 5, -1)\n",
    "state = game.next_state(state, 2, 1)\n",
    "state = game.next_state(state, 3, -1)\n",
    "# state = -state\n",
    "\n",
    "print(\"state:\")\n",
    "print_state(state)\n",
    "\n",
    "enc_state = encode_state(state)\n",
    "enc_state = torch.tensor(enc_state, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "model = ResNet(game, embd_size, hidden_size, num_blocks, params).to(device)\n",
    "print(\"untrained model result:\")\n",
    "quick_model_test(model, enc_state)\n",
    "\n",
    "model_checkpoint = torch.load(f\"./models/model_{game}_latest.pt\")\n",
    "model.load_state_dict(model_checkpoint[\"model\"])\n",
    "\n",
    "print(\"trained model result:\")\n",
    "quick_model_test(model, enc_state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Processing\n",
    "\n",
    "The MCTS class processes each state individualy resulting is a slow process of generating a training dataset. We can process states in batches to speed up the process.\n",
    "\n",
    "First, we start with the encoding states. We generalize it as follows to encode the states in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_state_parallel(states):\n",
    "    '''\n",
    "    b, m, n = states.shape\n",
    "    output size: b x 3 x m x n\n",
    "    '''\n",
    "    out = np.stack(\n",
    "        [states == 1, states == 0, states == -1]\n",
    "    ).astype(np.float32)\n",
    "    out = np.swapaxes(out, 0, 1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self, game, state, params, parent=None, parent_action=None, prior_prob=0, visit_count=0):\n",
    "        self.game = game\n",
    "        self.state = state\n",
    "        self.params = params\n",
    "        self.parent = parent\n",
    "        self.parent_action = parent_action\n",
    "        \n",
    "        self.children = []\n",
    "        \n",
    "        self.reward_sum = 0\n",
    "        self.visit_count = visit_count\n",
    "        self.prior_prob = prior_prob\n",
    "        \n",
    "    def ucb(self):\n",
    "        '''\n",
    "        Return a vector of UCBs of all children.\n",
    "        '''\n",
    "        children_visit_counts = np.array([child.visit_count for child in self.children])\n",
    "        children_reward_sum = np.array([child.reward_sum for child in self.children])\n",
    "        children_prior_probs = np.array([child.prior_prob for child in self.children])\n",
    "\n",
    "        exploration_factor = self.params[\"exploration_factor\"]\n",
    "        exploration = np.sqrt(self.visit_count) / (1.0 + children_visit_counts)\n",
    "        expected_reward = -np.divide(children_reward_sum, children_visit_counts,\n",
    "                                     where=children_visit_counts!=0)\n",
    "        \n",
    "        return expected_reward + exploration_factor * children_prior_probs * exploration\n",
    "     \n",
    "    def select(self):\n",
    "        k = np.argmax(self.ucb())\n",
    "        return self.children[k]\n",
    "    \n",
    "    def is_fully_expanded(self):\n",
    "        return len(self.children) > 0\n",
    "    \n",
    "    def create_child(self, action, prob):\n",
    "        player = self.game.first_player\n",
    "        other_player = self.game.opponent(player)\n",
    "\n",
    "        child_state = self.game.next_state(self.state.copy(), action, player)\n",
    "        child_state = self.game.neutral_perspective(child_state, other_player)\n",
    "        \n",
    "        child = Node(self.game, child_state, self.params, self, action, prob)\n",
    "        return child\n",
    "    \n",
    "    def expand(self, policy):\n",
    "        self.children = [self.create_child(a, p) for a, p in enumerate(policy) if p != 0]\n",
    "            \n",
    "    def backward(self, reward):\n",
    "        node = self\n",
    "        while node is not None:            \n",
    "            node.reward_sum += reward\n",
    "            node.visit_count += 1\n",
    "            reward = self.game.opponent_reward(reward)\n",
    "            node = node.parent\n",
    "\n",
    "class MCTS(object):\n",
    "    def __init__(self, game, model, params):\n",
    "        self.game = game\n",
    "        self.model = model\n",
    "        self.params = params\n",
    "        \n",
    "    def select(self, node):\n",
    "        while node.is_fully_expanded():\n",
    "            node = node.select()\n",
    "        return node\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def best_policies(self, states):\n",
    "        roots = [Node(self.game, state, self.params, visit_count=1) for state in states]\n",
    "        num_iters = self.params[\"num_iters\"]\n",
    "        \n",
    "        for _ in range(num_iters):\n",
    "            batch_nodes = []\n",
    "            for root in roots:\n",
    "                node = self.select(root)\n",
    "\n",
    "                if self.game.is_over(node.state, node.parent_action):\n",
    "                    reward = self.game.reward(node.state)\n",
    "                    reward = self.game.opponent_reward(reward)\n",
    "                    node.backward(reward)\n",
    "                else:\n",
    "                    batch_nodes.append(node)\n",
    "            \n",
    "            if len(batch_nodes) == 0:\n",
    "                continue\n",
    "\n",
    "            batch_states = np.array([node.state for node in batch_nodes])\n",
    "            enc_states = encode_state_parallel(batch_states)\n",
    "            enc_states = torch.tensor(enc_states, device=self.params[\"device\"])\n",
    "\n",
    "            logits, rewards = self.model(enc_states)\n",
    "            # mask out illegal moves\n",
    "            logits[batch_states[:, 0, :] != 0] = -np.inf\n",
    "            policies = F.softmax(logits, dim=1).detach().cpu().numpy()\n",
    "            \n",
    "            for node, policy, reward in zip(batch_nodes, policies, rewards):\n",
    "                node.expand(policy)\n",
    "                node.backward(reward.item())\n",
    "        \n",
    "        return self.compute_policies(roots)\n",
    "    \n",
    "    def compute_policies(self, roots):\n",
    "        out = np.zeros((len(roots), self.game.ncols))\n",
    "\n",
    "        for i, root in enumerate(roots):\n",
    "            for child in root.children:\n",
    "                out[i, child.parent_action] = child.visit_count\n",
    "\n",
    "        out /= np.sum(out, axis=1, keepdims=True)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParallelPlay(object):\n",
    "    def __init__(self, game):\n",
    "        self.game = game\n",
    "        self.current_state = game.init_state()\n",
    "        self.states = []\n",
    "        self.policies = []\n",
    "        self.rewards = []\n",
    "        self.players = []  \n",
    "\n",
    "def generate_data(mcts, num_threads):\n",
    "    '''\n",
    "    Runs `num_threads` games in parallel and generates data from all the states\n",
    "    in all the games.\n",
    "    outout: (states, policies, rewards)\n",
    "    '''\n",
    "    game = mcts.game\n",
    "    player = game.first_player\n",
    "    par_plays = [ParallelPlay(game) for _ in range(num_threads)]\n",
    "\n",
    "    # storing all states, policies, and rewards from all the threads.\n",
    "    out_states, out_policies, out_rewards = [], [], []\n",
    "    \n",
    "    while len(par_plays) > 0:\n",
    "        states = np.array([p.current_state for p in par_plays])\n",
    "        neutral_states = game.neutral_perspective(states, player)\n",
    "        policies = mcts.best_policies(neutral_states)\n",
    "        \n",
    "        for i in range(len(par_plays)-1, -1, -1):\n",
    "            par_plays[i].states.append(neutral_states[i])\n",
    "            par_plays[i].policies.append(policies[i])\n",
    "            par_plays[i].players.append(player)\n",
    "\n",
    "            action = np.random.choice(len(policies[i]), p=policies[i])\n",
    "            par_plays[i].current_state = game.next_state(par_plays[i].current_state, action, player)\n",
    "            \n",
    "            if game.is_over(par_plays[i].current_state, action):\n",
    "                out_states.extend(par_plays[i].states)\n",
    "                out_policies.extend(par_plays[i].policies)\n",
    "\n",
    "                reward = game.reward(par_plays[i].current_state)\n",
    "                out_rewards.extend([reward if p == player else game.opponent_reward(reward) for p in par_plays[i].players])\n",
    "\n",
    "                del par_plays[i]                \n",
    "        \n",
    "        player = game.opponent(player)\n",
    "        \n",
    "    return out_states, out_policies, out_rewards\n",
    "    \n",
    "def generate_dataset(mcts, num_self_plays, num_threads):\n",
    "    states, policies, rewards = [], [], []\n",
    "    \n",
    "    for _ in trange(num_self_plays // num_threads):\n",
    "        s, p, r = generate_data(mcts, num_threads)\n",
    "        states.extend(s)\n",
    "        policies.extend(p)\n",
    "        rewards.extend(r)\n",
    "    \n",
    "    states, policies, rewards = np.array(states), np.array(policies), np.array(rewards)\n",
    "    enc_states = encode_state_parallel(states)\n",
    "    \n",
    "    return enc_states, policies, rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = Connect4()\n",
    "\n",
    "embd_size = params[\"embd_size\"]\n",
    "hidden_size = params[\"hidden_size\"]\n",
    "num_blocks = params[\"num_blocks\"]\n",
    "device = params[\"device\"]\n",
    "model = ResNet(game, embd_size, hidden_size, num_blocks, params).to(device)\n",
    "\n",
    "mcts = MCTS(game, model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data = params[\"load_data\"]\n",
    "num_threads = params[\"num_threads\"]\n",
    "\n",
    "if load_data:\n",
    "    data_checkpoint = torch.load(f\"./data/{game}_data.pt\")\n",
    "    train_data = data_checkpoint[\"train_data\"]\n",
    "    eval_data = data_checkpoint[\"eval_data\"]\n",
    "else:\n",
    "    num_self_plays = params[\"num_self_plays\"]\n",
    "    %prun -T prun.txt train_data = generate_dataset(mcts, num_self_plays, num_threads)\n",
    "    eval_data = generate_dataset(mcts, int(0.1 * num_self_plays), num_threads)\n",
    "    data_checkpoint = {\n",
    "        \"train_data\": train_data,\n",
    "        \"eval_data\": eval_data,\n",
    "    }\n",
    "    torch.save(data_checkpoint, f\"./data/{game}_data.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_model(model, eval_data, params):\n",
    "    device = params[\"device\"]\n",
    "\n",
    "    states, policies, rewards = eval_data\n",
    "\n",
    "    enc_states = torch.tensor(states, dtype=torch.float32, device=device)\n",
    "    target_policies = torch.tensor(policies, dtype=torch.float32, device=device)\n",
    "    target_rewards = torch.tensor(rewards, dtype=torch.float32, device=device).unsqueeze(1)\n",
    "\n",
    "    pred_logits, pred_rewards = model(enc_states)\n",
    "\n",
    "    pred_policies = F.softmax(pred_logits, dim=1)\n",
    "    policy_loss = F.cross_entropy(pred_policies, target_policies)\n",
    "    reward_loss = F.mse_loss(pred_rewards, target_rewards)\n",
    "    \n",
    "    return policy_loss.item(), reward_loss.item()\n",
    "\n",
    "def train_model(game, model, optimizer, train_data, eval_data, params, losses=None, num_models_to_save=1):\n",
    "    if losses is None:\n",
    "        losses = Losses()\n",
    "    \n",
    "    states, policies, rewards = train_data\n",
    "    num_epochs = params[\"num_epochs\"]\n",
    "    batch_size = params[\"batch_size\"]\n",
    "    device = params[\"device\"]\n",
    "    \n",
    "    for epoch in trange(num_epochs):\n",
    "        model.train()\n",
    "        batch_indices = np.random.choice(len(states), batch_size)\n",
    "        \n",
    "        enc_states = torch.tensor(states[batch_indices], dtype=torch.float32, device=device)\n",
    "        target_policies = torch.tensor(policies[batch_indices], dtype=torch.float32, device=device)\n",
    "        target_rewards = torch.tensor(rewards[batch_indices], dtype=torch.float32, device=device).unsqueeze(1)\n",
    "        \n",
    "        pred_logits, pred_rewards = model(enc_states)\n",
    "\n",
    "        pred_policies = F.softmax(pred_logits, dim=1)\n",
    "        policy_loss = F.cross_entropy(pred_policies, target_policies)\n",
    "        reward_loss = F.mse_loss(pred_rewards, target_rewards)\n",
    "        \n",
    "        losses.policy.train.append(policy_loss.item())\n",
    "        losses.reward.train.append(reward_loss.item())\n",
    "        \n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        policy_loss.backward(retain_graph=True)\n",
    "        reward_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (epoch + 1) % (num_epochs/num_models_to_save) == 0:\n",
    "            model_checkpoint = {\n",
    "                \"model\": model.state_dict(),\n",
    "                \"optimizer\": optimizer.state_dict(),\n",
    "            }\n",
    "            torch.save(model_checkpoint, f\"./models/{game}_{epoch+1}.pt\")\n",
    "        \n",
    "        model.eval()\n",
    "        policy_loss, reward_loss = eval_model(model, eval_data, params)\n",
    "        losses.policy.eval.append(policy_loss)\n",
    "        losses.reward.eval.append(reward_loss)\n",
    "        \n",
    "    return losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(object):\n",
    "    def __init__(self):\n",
    "        self.train = []\n",
    "        self.eval = []\n",
    "\n",
    "class Losses(object):\n",
    "    def __init__(self):\n",
    "        self.policy = Loss()\n",
    "        self.reward = Loss()\n",
    "\n",
    "losses = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = params[\"load_model\"]\n",
    "num_epochs = params[\"num_epochs\"]\n",
    "lr = params[\"lr\"]\n",
    "weight_decay = params[\"weight_decay\"]\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "if load_model:\n",
    "    model_checkpoint = torch.load(f\"./models/{game}_{num_epochs}.pt\")\n",
    "    model = model_checkpoint[\"model\"]\n",
    "    optimizer = model_checkpoint[\"optimizer\"]\n",
    "else:\n",
    "    num_models_to_save = 1\n",
    "    losses = train_model(game, model, optimizer, train_data, eval_data, params, losses, \n",
    "                num_models_to_save=num_models_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses.policy.train)\n",
    "plt.plot(losses.policy.eval)\n",
    "plt.legend([\"training loss\", \"evaluation loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses.reward.train)\n",
    "plt.plot(losses.reward.eval)\n",
    "plt.legend([\"training loss\", \"evaluation loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = Connect4()\n",
    "state = game.init_state()\n",
    "player = game.first_player\n",
    "\n",
    "embd_size = params[\"embd_size\"]\n",
    "hidden_size = params[\"hidden_size\"]\n",
    "num_blocks = params[\"num_blocks\"]\n",
    "device = params[\"device\"]\n",
    "model = ResNet(game, embd_size, hidden_size, num_blocks, params).to(device)\n",
    "\n",
    "num_epochs = params[\"num_epochs\"]\n",
    "model_checkpoint = torch.load(f\"./models/{game}_100.pt\")\n",
    "model.load_state_dict(model_checkpoint[\"model\"])\n",
    "model.eval()\n",
    "\n",
    "mcts = MCTS(game, model, params)\n",
    "\n",
    "while True:\n",
    "    print_state(state)\n",
    "    available_actions = game.available_actions(state)\n",
    "    \n",
    "    if len(available_actions) == 0:\n",
    "        print(\"draw!\")\n",
    "        break\n",
    "\n",
    "    print(f\"player {players[player]} to move...\")\n",
    "    print(f\"available moves: \")\n",
    "\n",
    "    if player == game.first_player:\n",
    "        action = int(input(\"provide your move: \"))\n",
    "    else:\n",
    "        neutral_state = game.neutral_perspective(state, player)\n",
    "\n",
    "        policy = mcts.best_policies([neutral_state])\n",
    "        policy = policy[0]\n",
    "\n",
    "        # enc_neutral_state = torch.tensor(encode_state(neutral_state), dtype=torch.float32).unsqueeze(0)        \n",
    "        # logit, reward = model(enc_neutral_state)\n",
    "        # print(f\"predicted reward: {reward.item()}\")\n",
    "        # policy = F.softmax(logit, dim=1).squeeze(0).detach().cpu().numpy()\n",
    "\n",
    "        action = np.argmax(policy)\n",
    "        \n",
    "        plt.bar(range(len(policy)), policy)\n",
    "        plt.show()\n",
    "    \n",
    "    state = game.next_state(state, action, player)\n",
    "    \n",
    "    if game.won(state, action):\n",
    "        print_state(state)\n",
    "        print(f\"player {players[player]} won!\")\n",
    "        break\n",
    "    \n",
    "    player = game.opponent(player)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = torch.load(f\"./data/{game}_losses.pt\")\n",
    "\n",
    "eval_size = 100\n",
    "plt.plot(torch.tensor(losses.policy.train).view(-1, eval_size).mean(axis=1))\n",
    "plt.plot(torch.tensor(losses.policy.eval).view(-1, eval_size).mean(axis=1))\n",
    "plt.legend([\"training loss\", \"evaluation loss\"])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(torch.tensor(losses.reward.train).view(-1, eval_size).mean(axis=1))\n",
    "plt.plot(torch.tensor(losses.reward.eval).view(-1, eval_size).mean(axis=1))\n",
    "plt.legend([\"training loss\", \"evaluation loss\"])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s, p, r = torch.load(f\"./data/data_{game}_4.pt\")\n",
    "s, p, r = np.array(s), np.array(p), np.array(r)\n",
    "print(s.shape, p.shape, r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 0\n",
    "skip = False\n",
    "\n",
    "for k in range(len(s)):\n",
    "    state = decode_state(s[k])\n",
    "    \n",
    "    if np.sum(state != 0) == 0 and skip:\n",
    "        break\n",
    "\n",
    "    print_state(state)\n",
    "    skip = True\n",
    "    \n",
    "    plt.bar(range(len(p[k])), p[k])\n",
    "    plt.show()\n",
    "    \n",
    "    print(r[k])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
